# Forward Propagation and Backpropagation in Neural Networks

Neural networks are trained using two key processes: **Forward Propagation** and **Backpropagation**. These processes allow the network to learn by adjusting the weights to minimize the error between predicted and actual outputs.

---

## 1. **Forward Propagation**

Forward propagation is the process by which the input data passes through the network layer by layer to produce an output.

### Steps:

1. **Input Layer:**
   - The input data \( X \) is fed into the network.

2. **Weighted Sum:**
   - For each layer, the weighted sum of inputs is computed using the following formula:
   \[
   z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}
   \]
   - Where:
     - \( z^{(l)} \) is the weighted sum at layer \( l \)
     - \( W^{(l)} \) is the weight matrix for layer \( l \)
     - \( a^{(l-1)} \) is the activation from the previous layer
     - \( b^{(l)} \) is the bias term for layer \( l \)

3. **Activation Function:**
   - The activation function is applied to introduce non-linearity. A common activation function is the **ReLU** (Rectified Linear Unit) or **Sigmoid** function:
     \[
     a^{(l)} = \sigma(z^{(l)})
     \]
     - Where \( a^{(l)} \) is the activation output of the current layer.
     - For ReLU:
       \[
       \sigma(z) = \max(0, z)
       \]
     - For Sigmoid:
       \[
       \sigma(z) = \frac{1}{1 + e^{-z}}
       \]

4. **Output Layer:**
   - For the final layer, the result \( a^{(L)} \) (where \( L \) is the last layer) is compared with the expected output. If itâ€™s a classification problem, the output could be probabilities (using the softmax function).

### Example:

In a neural network, if you have inputs \( x_1, x_2 \) and two layers, the output for the first layer is:
\[
z_1^{(1)} = W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + b_1^{(1)}
\]
Then, apply an activation function \( \sigma(z_1^{(1)}) \) to get \( a_1^{(1)} \), and so on for the next layer until you get the final output.

---

## 2. **Backpropagation**

Backpropagation is the algorithm used to minimize the error of the network by adjusting the weights in the network according to the gradient of the loss function with respect to each weight.

### Steps:

1. **Loss Calculation:**
   - The first step is to calculate the **loss** (error) between the predicted output \( \hat{y} \) and the true output \( y \). A common loss function for classification problems is **Cross-Entropy Loss**:
   \[
   \mathcal{L}(y, \hat{y}) = -\sum_i y_i \log(\hat{y}_i)
   \]
   - For regression problems, **Mean Squared Error (MSE)** is often used:
   \[
   \mathcal{L}(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
   \]

2. **Gradient Calculation:**
   - Backpropagation works by calculating the gradient of the loss with respect to the weights using the **chain rule** of calculus.
   
   - The gradient for the weight \( W \) at layer \( l \) is computed as:
   \[
   \frac{\partial \mathcal{L}}{\partial W^{(l)}} = \frac{\partial \mathcal{L}}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l)}}{\partial W^{(l)}}
   \]
   - Where:
     - \( \frac{\partial \mathcal{L}}{\partial a^{(l)}} \) is the gradient of the loss with respect to the activation at layer \( l \).
     - \( \frac{\partial a^{(l)}}{\partial z^{(l)}} \) is the derivative of the activation function.
     - \( \frac{\partial z^{(l)}}{\partial W^{(l)}} \) is the derivative of the weighted sum with respect to the weight.
   
3. **Weight Update:**
   - Once the gradient is calculated, the weights are updated using **gradient descent** or some variant like **Adam**:
   \[
   W^{(l)} = W^{(l)} - \eta \frac{\partial \mathcal{L}}{\partial W^{(l)}}
   \]
   - Where \( \eta \) is the learning rate, a small positive number.

4. **Bias Update:**
   - Similarly, the bias terms are updated using the gradient with respect to the bias:
   \[
   b^{(l)} = b^{(l)} - \eta \frac{\partial \mathcal{L}}{\partial b^{(l)}}
   \]

### Chain Rule for Backpropagation

Backpropagation makes extensive use of the chain rule to compute gradients. For example, if you have:
\[
\frac{\partial \mathcal{L}}{\partial W^{(l)}} = \frac{\partial \mathcal{L}}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l)}}{\partial W^{(l)}}
\]
The chain rule allows the network to backtrack layer by layer and compute how each parameter contributed to the error.

### Example of Backpropagation

Suppose you have the following gradient for the final output layer \( L \):
\[
\delta^{(L)} = \frac{\partial \mathcal{L}}{\partial z^{(L)}} = a^{(L)} - y
\]
You can backpropagate this error to previous layers:
\[
\delta^{(l)} = \left( W^{(l+1)} \right)^T \delta^{(l+1)} \odot \sigma'(z^{(l)})
\]
Where \( \odot \) represents the element-wise multiplication, and \( \sigma'(z^{(l)}) \) is the derivative of the activation function at layer \( l \).

---

### Summary of Formulas:

1. **Forward Propagation:**
   \[
   z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}
   \]
   \[
   a^{(l)} = \sigma(z^{(l)})
   \]

2. **Backpropagation:**
   \[
   \frac{\partial \mathcal{L}}{\partial W^{(l)}} = \frac{\partial \mathcal{L}}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l)}}{\partial W^{(l)}}
   \]
   \[
   W^{(l)} = W^{(l)} - \eta \frac{\partial \mathcal{L}}{\partial W^{(l)}}
   \]

These two processes work together to minimize the loss function and train the neural network to make accurate predictions.
